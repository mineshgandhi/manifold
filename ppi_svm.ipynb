{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aboriginal-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import manifold, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from grakel.kernels import NeighborhoodSubgraphPairwiseDistance\n",
    "from grakel.kernels import WeisfeilerLehman\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse, io\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import mat4py\n",
    "import glob\n",
    "import pandas as pd\n",
    "from grakel import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "brave-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "smoking-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 1)\n",
      "(232, 232)\n"
     ]
    }
   ],
   "source": [
    "path = 'PPI'\n",
    "files = glob.glob(path + '/*.csv')\n",
    "\n",
    "lists = []\n",
    "\n",
    "for filename in files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=None)\n",
    "    lists.append(df)\n",
    "    \n",
    "frame = pd.concat(lists, axis=0, ignore_index=True)\n",
    "data_ = clean_dataset(frame)\n",
    "\n",
    "labels = pd.read_csv('ppi_labels.csv').T\n",
    "# labels = labels.values.flatten()\n",
    "\n",
    "data_, labels = data_.align(labels, axis=1, fill_value=0)\n",
    "\n",
    "labels = labels.T\n",
    "print(labels.shape)\n",
    "print(data_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fifth-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train/test (1000/100 instances)\n",
      "      0    1    2    3    4    5    6    7    8    9    ...  222  223  224  \\\n",
      "2883  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  ...  1.0  0.0  0.0   \n",
      "2884  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2885  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2886  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2887  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3028  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3029  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3030  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "3031  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3032  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "      225  226  227  228  229  230  231  \n",
      "2883  1.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2884  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2885  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2886  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2887  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "3028  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3029  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3030  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3031  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3032  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[150 rows x 232 columns]       0    1    2    3    4    5    6    7    8    9    ...  222  223  224  \\\n",
      "3033  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3034  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3035  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
      "3036  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
      "3037  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3110  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3111  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3112  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3113  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3114  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "      225  226  227  228  229  230  231  \n",
      "3033  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3034  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3035  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3036  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3037  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "3110  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3111  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3112  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3113  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3114  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[82 rows x 232 columns] (150, 1) (82, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting dataset into train/test (1000/100 instances)\")\n",
    "graphs_train, graphs_test = data_[:150], data_[150:232]\n",
    "y_train, y_test = labels[:150], labels[150:232]\n",
    "\n",
    "# # split a dataset into train and test sets\n",
    "# from sklearn.datasets import make_blobs\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # create dataset\n",
    "# X, y = make_blobs(n_samples=1000)\n",
    "# split into train test sets\n",
    "# graphs_train, graphs_test, y_train, y_test = train_test_split(lists, labels, test_size=0.33)\n",
    "print(graphs_train, graphs_test, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "massive-adaptation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "each element of X must be either a graph object or a list with at least a graph like object and node labels dict \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e0a4a4cfc354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Construct kernel matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mK_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mK_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/1C10BE5A463AA9E0/ProjectsDir/ML/Manifold Learning/venv/lib/python3.8/site-packages/grakel/kernels/weisfeiler_lehman.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'transform input cannot be None'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mkm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/1C10BE5A463AA9E0/ProjectsDir/ML/Manifold Learning/venv/lib/python3.8/site-packages/grakel/kernels/weisfeiler_lehman.py\u001b[0m in \u001b[0;36mparse_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                     raise TypeError('each element of X must be either a ' +\n\u001b[0m\u001b[1;32m    175\u001b[0m                                     \u001b[0;34m'graph object or a list with at least '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                                     \u001b[0;34m'a graph like object and node labels '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: each element of X must be either a graph object or a list with at least a graph like object and node labels dict \n"
     ]
    }
   ],
   "source": [
    "# Initialize a Weisfeiler-Lehman subtree kernel\n",
    "gk = WeisfeilerLehman(n_iter=1, normalize=False)\n",
    "\n",
    "# Construct kernel matrices\n",
    "K_train = gk.fit_transform(graphs_train)\n",
    "K_test = gk.transform(graphs_test)\n",
    "\n",
    "# Train an SVM classifier and make predictions\n",
    "clf = SVC(kernel='precomputed')\n",
    "clf.fit(K_train, y_train) \n",
    "y_pred = clf.predict(K_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(\"Accuracy:\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "amber-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing kernel matrics\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "each element of X must have either a graph with labels for node and edge or 3 elements consisting of a graph type object, labels for vertices and labels for edges.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7f4306174afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing kernel matrics\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mK_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mK_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done in %0.3fs\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/1C10BE5A463AA9E0/ProjectsDir/ML/Manifold Learning/venv/lib/python3.8/site-packages/grakel/kernels/neighborhood_subgraph_pairwise_distance.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_method_calling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/1C10BE5A463AA9E0/ProjectsDir/ML/Manifold Learning/venv/lib/python3.8/site-packages/grakel/kernels/kernel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`fit` input cannot be None'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Return the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/1C10BE5A463AA9E0/ProjectsDir/ML/Manifold Learning/venv/lib/python3.8/site-packages/grakel/kernels/neighborhood_subgraph_pairwise_distance.py\u001b[0m in \u001b[0;36mparse_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    137\u001b[0m                               x.get_labels(purpose=\"adjacency\", label_type=\"edge\"))\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                     raise TypeError('each element of X must have either ' +\n\u001b[0m\u001b[1;32m    140\u001b[0m                                     \u001b[0;34m'a graph with labels for node and edge '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                                     \u001b[0;34m'or 3 elements consisting of a graph '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: each element of X must have either a graph with labels for node and edge or 3 elements consisting of a graph type object, labels for vertices and labels for edges."
     ]
    }
   ],
   "source": [
    "# Initialize neighborhood subgraph pairwise distance kernel\n",
    "gk = NeighborhoodSubgraphPairwiseDistance(r=3, d=2)\n",
    "\n",
    "print(\"Computing kernel matrics\\n\")\n",
    "t0 = time()\n",
    "K_train = gk.fit_transform(graphs_train)\n",
    "K_test = gk.transform(graphs_test)\n",
    "print(\"done in %0.3fs\\n\" % (time() - t0))\n",
    "\n",
    "print(\"Classifying digits\\n\")\n",
    "# Initialize SVM\n",
    "clf = SVC(kernel='precomputed')\n",
    "\n",
    "# Fit on the train Kernel\n",
    "clf.fit(K_train, y_train)\n",
    "\n",
    "# Predict and test.\n",
    "y_pred = clf.predict(K_test)\n",
    "\n",
    "# Calculate accuracy of classification.\n",
    "print(\"Classification accuracy: %0.2f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-croatia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/sampleSubmission.csv\")\n",
    "training_labels = LabelEncoder().fit_transform(train['target'])\n",
    "\n",
    "# SVMs tend to like features that look similar to ~ N(0,1), so let's stabilise\n",
    "# the long tails\n",
    "train_features = train.drop('target', axis=1)\n",
    "train_features[train_features > 4] = 4\n",
    "\n",
    "model = LinearSVC().fit(train_features, training_labels)\n",
    "\n",
    "scores = model.decision_function(test)\n",
    "predictions = 1.0 / (1.0 + np.exp(-scores))\n",
    "row_sums = predictions.sum(axis=1)\n",
    "predictions_normalised = predictions / row_sums[:, np.newaxis]\n",
    "\n",
    "# create submission file\n",
    "prediction_DF = pd.DataFrame(predictions_normalised, index=sample_submission.id.values, columns=sample_submission.columns[1:])\n",
    "prediction_DF.to_csv('svc_submission.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-research",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
